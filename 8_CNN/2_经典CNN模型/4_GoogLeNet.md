# GoogLeNet

GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。这篇论文的一个重点是**解决了什么样大小的卷积核最合适的问题**。本文的一个观点是，有时**使用不同大小的卷积核组合**是有利的。

![图 3](../../images/b2e05a12ecf51debe0f6f0af5f3670917d9ae8e9a96dfadd668bd0a2b75bbac0.png)  

在$GoogLeNet$中，基本的卷积块被称为$Inception$块。这很可能得名于电影《盗梦空间》（Inception），因为电影中的一句话“我们需要走得更深”（$We\ need\ to\ go\ deeper$）。

![图 4](../../images/31c3f68996ae0a707e8887de6f604fed0c3700e518889e44666a40f323ad6528.png)  

> 白色的1*1卷积是用来降低通道数的，**通过降低通道数来控制模型复杂度（降低运算次数）**，如下图所示：
> ![图 4](../../images/78d7cf78841889892eb578c025e59e073d00f56a6779d4e2f44c495616054723.png)  
> 蓝色的卷积和池化是用来抽取信息的

前三条路径使用窗口大小为1X1、3X3和5X5的卷积层，从不同空间大小中提取信息。中间的两条路径在输入上执行卷积，以减少通道数，从而降低模型的复杂性。第四条路径使用最大汇聚层，然后使用1X1卷积层来改变通道数。这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。
![图 5](../../images/c9fa6ee898fc6a956a99e3a44672a435188cd777bae5bc3689263f511707e68b.png)  

![图 6](../../images/6c857970ef5d1c422a2396c7b0f424885a9e4455cdef7572dcb5196ada800519.png)  

![图 7](../../images/9f0f58db902751743ade75d007adc7f9de235cc7024b9ec93566e1cb565681db.png)  

![图 8](../../images/e348117630e7a1800811a18348c2dafb75638300ace96de6caf07dc5c76f8731.png)  
