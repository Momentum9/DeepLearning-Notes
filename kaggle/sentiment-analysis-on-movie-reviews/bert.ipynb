{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: W&B API key is configured. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import wandb\n",
    "# wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_train = pd.read_csv('./sentiment-analysis-on-movie-reviews/train.tsv/train.tsv', sep='\\t')\n",
    "data_test = pd.read_csv('./sentiment-analysis-on-movie-reviews/test.tsv/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取phrase:x和label:y，并划分训练集为训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data_train['Phrase'].values.tolist(), \n",
    "                                                      data_train['Sentiment'].values.tolist(), \n",
    "                                                      test_size=0.25, \n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 向量化\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, num_labels=5)  # 五种情绪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(x_train), truncation=True, padding=True, return_tensors='pt')  # max_length=512\n",
    "val_encodings = tokenizer(list(x_valid), truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将向量化后的data封装成torch形式的dataset\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 获取每一个图片\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}  # TODO 本来就是tensor了啊\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item  # 构建的data包括input_ids, attention_mask, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class SentimentTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}  # TODO 本来就是tensor了啊\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成dataloaders (tokenized data -> torch dataset)\n",
    "train_dataset = SentimentDataset(train_encodings, y_train)\n",
    "val_dataset = SentimentDataset(val_encodings, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(117045, 39015)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义度量函数\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true=labels, y_pred=predictions),\n",
    "        'f1_score': f1_score(labels, predictions, average='weighted')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='steps',  # evaluation strategy to adopt during training\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5, # default=5e-5\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='tensorboard'  # 日志展示方式吧  wandb可选\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 基于Bert进行finetune\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mBertForSequenceClassification\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_pretrained(checkpoint, num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m) \u001B[38;5;66;03m# 5类\u001B[39;00m\n\u001B[1;32m      3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel, \u001B[38;5;66;03m# 实例化的模型\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args, \u001B[38;5;66;03m# 训练参数\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics, \u001B[38;5;66;03m# 评价指标\u001B[39;00m\n\u001B[1;32m      9\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "# 基于Bert进行finetune\n",
    "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=5) # 5类\n",
    "trainer = Trainer(\n",
    "    model=model, # 实例化的模型\n",
    "    args=training_args, # 训练参数\n",
    "    train_dataset=train_dataset, # 训练集\n",
    "    eval_dataset=val_dataset, # 验证集\n",
    "    compute_metrics=compute_metrics, # 评价指标\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# 开训\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()  # 开训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate()  \u001B[38;5;66;03m# 在验证集上进行评估\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()  # 在验证集上进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上进行预测\n",
    "x_test = data_test['Phrase'].values.tolist()  # 没有sentiment\n",
    "test_encodings = tokenizer(x_test, truncation=True, padding=True, return_tensors='pt')\n",
    "test_dataset = SentimentTestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(test_dataset)  \u001B[38;5;66;03m# 预测结果\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)  # 预测结果"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "PredictionOutput(predictions=array([[-2.8357358,  0.663277 ,  2.5971327,  1.6330429, -2.437308 ],\n       [-3.0690255,  0.2920592,  2.5112534,  1.9263854, -2.1462643],\n       [-3.0371137, -0.2481   ,  5.0157795,  1.8348434, -2.6696217]],\n      dtype=float32), label_ids=None, metrics={'test_runtime': 0.0925, 'test_samples_per_second': 32.416, 'test_steps_per_second': 10.805})"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "probs = torch.from_numpy(preds[0]).softmax(1)  # 转为概率"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 2, 2, ..., 1, 1, 1])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = probs.numpy()\n",
    "y_labels = predictions.argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "       PhraseId  SentenceId  \\\n0        156061        8545   \n1        156062        8545   \n2        156063        8545   \n3        156064        8545   \n4        156065        8545   \n...         ...         ...   \n66287    222348       11855   \n66288    222349       11855   \n66289    222350       11855   \n66290    222351       11855   \n66291    222352       11855   \n\n                                                  Phrase  Sentiment  \n0      An intermittently pleasing but mostly routine ...          2  \n1      An intermittently pleasing but mostly routine ...          2  \n2                                                     An          2  \n3      intermittently pleasing but mostly routine effort          2  \n4             intermittently pleasing but mostly routine          2  \n...                                                  ...        ...  \n66287             A long-winded , predictable scenario .          1  \n66288               A long-winded , predictable scenario          1  \n66289                                    A long-winded ,          1  \n66290                                      A long-winded          1  \n66291                               predictable scenario          1  \n\n[66292 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>156061</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156062</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156063</td>\n      <td>8545</td>\n      <td>An</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>156064</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine effort</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156065</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66287</th>\n      <td>222348</td>\n      <td>11855</td>\n      <td>A long-winded , predictable scenario .</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66288</th>\n      <td>222349</td>\n      <td>11855</td>\n      <td>A long-winded , predictable scenario</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66289</th>\n      <td>222350</td>\n      <td>11855</td>\n      <td>A long-winded ,</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66290</th>\n      <td>222351</td>\n      <td>11855</td>\n      <td>A long-winded</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66291</th>\n      <td>222352</td>\n      <td>11855</td>\n      <td>predictable scenario</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>66292 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "data_test.loc[:, 'Sentiment'] = y_labels\n",
    "submit_data = data_test.loc[:, ['PhraseId', 'Sentiment']]\n",
    "submit_data.to_csv('submission_bert.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
