# DDPM and DDIM

## DDPM

![picture 4](../images/f957787236d56132496c263bacc58fed52569cbb77f341e10b53078c8396a5b5.png)  

参考满足马尔科夫链假设的条件概率形式

### diffusion process

$\beta=\textit{np.linspace}(0.0001, 0.02, T)$
$\alpha=1-\beta, \bar{\alpha}=\prod\alpha_i$

![picture 2](../images/a8f7c296b627f4dbf087e62f5e72b679f84a778531015fac3aecbcb4b5e6df82.png)  
![picture 3](../images/882fe65279a9a8d29cf5d15c831fa459e00f241751885456ce9212afb8a15dbd.png)  

上面的线性过程，也可以看成是从一个高斯分布中采样，具体实现也是借助重参数化的技巧。

![picture 0](../images/6b54db90002be325e7e794f947256f12db1a6e383faab4bfe95a7526c48ce059.png)  

![picture 1](../images/6c9ced4f72fa5519802eee7a97b38416ebfbd6e340911da6efdd48355f5e8a5e.png)  

### inverse diffusion process

**训练过程**
我们希望$q(x_{t-1}|x_t)$，但没法推。所以使用神经网络$p_\theta(x_{t-1}|x_t)$来近似。
$q(x_{t-1}|x_t,x_0)$是可以推出来的，需要有x_0。
![picture 10](../images/6e84e4b3d74ec1b17ce3af6326a186c83e836a0a147e7aea14e061b46fc948f5.png)  
应该是训练阶段可以直接拿到x0然后训练学习分布用的

---

**采样过程**
![picture 11](../images/91f95ba919eb12eb22d6e294870991e36db6e9a6c8ebe6d7e150ccf8c29add90.png)  

![picture 12](../images/9bde27a9052a3f8d4497c8aab4b79825ee5f41996b07dc8f4c46c4c73cde9d08.png)  

![picture 13](../images/9e0a7af161ed0ba244b9fd72782f9c82a3fb199cd607d9303569f37eb6589ded.png)  

![picture 8](../images/bed5d981ca1de66dfd92f475f202beedc11d339ca330f27899a84a1e6ae1d23a.png)  

---
![picture 14](../images/ccd07974f1a9a4ae2f0a3e042fb799809ad8a5ca9bdc2db4573e82ebaf5db926.png)  
![picture 15](../images/b664cc1d7c68013bf9e6a555db87beab21f7d3b6691ae3eaf841a12f56d6a79b.png)  

---

![picture 20](../images/d4841956c5a7719d6a65e5f2aa49fe145f68cbcf829f82951b924c78997af685.png)  



## DDIM

扔掉马尔科夫假设
![picture 16](../images/aec68b08687e1d916c5d8e1fa64fe5cdfc834b7aca499c20b8afcf310630420c.png)  
![picture 17](../images/03d3b9bc64b68bfd41700bfad7a1d78d00d86c0bd6bd1d296cfa3e7abc525471.png)  

![picture 19](../images/5708fd7a348efc73c178038a8c1e1d63bcb782944274672f1904dacbe016aba5.png)  
