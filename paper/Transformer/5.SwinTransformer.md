# Note

[toc]

## 解决了什么问题

ViT在视觉领域只能用于分类，而SwinTransformer证明了transformer可作为视觉领域的通用骨干网络（包括分类、检测、分割和视屏等领域）

ViT将图片打成16*16的patch，每个patch自始至终代表的尺寸一样

> 对于检测任务，**多尺度的特征**是非常重要的，比如FPN将多个卷积层出来的特征的感受野是不一样的，能抓住物体不用尺度的特征，能很好地处理物体不同尺度的问题。
> 对于分割任务，UNet对于处理物体不同尺寸的问题，提出了skip connection的方法。

ViT只能用于单一尺寸，不适合处理密集预测型的任务。此外ViT的自注意力始终在整张图上进行，是全局建模，其复杂度是图像的平方倍，复杂度太高。

SwinTransformer在小窗口内计算自注意力，只需保证小窗口大小固定（该窗口内自注意力计算复杂度固定），那复杂度和图像的大小成线性关系。（利用了局部性理论：语义相近的不同物体大概率还是出现在相连的地方）

ST中的Patch Merging类似于池化层，使感受野增大，抓住了多尺度特征

ST在连续的自注意力层之间Shift Windows，使m层中某窗口中的像素在m+1层可能移动到另一个窗口，这样就可以和其他像素进行互动，拥有了更大的感受野