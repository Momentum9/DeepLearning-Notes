# Note

## 生成类任务

**目标**：估计分布函数P(x)，然后从分布函数中采样x
**难点**：**样本点太少，而我们要去预测看不见的点的概率密度**。由于维度诅咒：样本点再多，也没有我的样本空间大；
> 如果有足够多的样本点，能够覆盖所有的x，并且所有样本点都采样足够多次，那么可以直接统计出每个样本点x的概率密度；

**解决方法**：加入人类设定的先验$prior$知识，限制搜索空间，使得规模能被计算机计算。

- 比如对于一些样本点求其拟合函数：加入先验拟合函数为二次函数，那就大大简化了
- GPT的先验：对于词表示相近的词，他们产生的句子也是相近的
- GAN的先验：**假定数据的样本点x的分布可通过正态分布来生成出来；**

## VAE

VAE的先验：假定数据的样本点x的分布可通过正态分布来生成出来，和GAN一样。但解决方案不一样
GAN的方法：用这个生成器去采样一些z，产生一些采样生成的$\tilde{x}$，然后用采样生成的$\tilde{x}$的分布和数据集真实的x的分布计算KL散度。
VAE的方法：从单个数据点的角度优化，即将数据集中的所有样本(i.i.d)的概率最大化（最大似然估计的思想） 也就是让p(x)最大
$$
P(x) = \prod p(x_i)
$$

实践中往往优化log对数似然$\sum logp(x_i)$，但是如何优化这个似然函数？我们现在只有生成器，他可以生成数据，但是想知道每个数据的概率是多少是没办法的。
此时，有一种最大化似然函数的方法提出：找到一个**下界（ELBO）**，当**最大化最大似然函数下界的时候，这个似然函数也就变大了**
$$
ELBO : P(x) ≥ -KL(q_z(.)||p_{x,z}(x,.))
，其中z是一个任意的概率分布
$$

---
GAN
给一个**随机噪声z**，生成器G会生成图片，我们希望生成一张比较真实的图片。然后将这个生成的图片和真实的图片都给判别器D，让判别器去判断哪个是真的哪个是假的。双方都不断提升自己。让图片尽可能地真实，保真度很高！训练不够稳定！生成图片的创造性不太好！不是一个概率模型，你也不知道他做了什么。

AE
主要目的是学latent code特征的，然后拿去做分类、检测等任务。也就是说他学到的不是概率分布，无法对其进行采样，不能做生成任务

VAE
中间学的是分布，然后采样一个z出来。训练好模型后，可以扔掉encoder，直接采样就可以decoder生成出来图片了。
因为学的是概率分布，然后从分布中抽样，所以生成图片的创造性很好！

VQ-VAE
vector-quantised把VAE做量化；VAE很难把模型做大，中间那个分布也不是很好学；所以VQVAE就不去学那个分不了，取而代之用一个codebook代替
