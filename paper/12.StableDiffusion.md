# Stable Diffusion

LDMsæä¾›äº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶å›¾ç‰‡ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•è®¡ç®—æ›´åŠ é«˜æ•ˆã€æ§åˆ¶æ¡ä»¶æ›´åŠ çµæ´»ã€‚

[toc]

## è¡¥å……çŸ¥è¯†

### é«˜é¢‘ä¿¡æ¯å’Œä½é¢‘ä¿¡æ¯

å›¾åƒé¢‘ç‡æ˜¯è¡¨ç¤ºå›¾åƒä¸­ç°åº¦å˜åŒ–å‰§çƒˆç¨‹åº¦çš„æŒ‡æ ‡ã€‚å›¾åƒä½é¢‘ä¿¡æ¯è¡¨ç¤ºå›¾åƒä¸­ç°åº¦å€¼å˜åŒ–ç¼“æ…¢çš„åŒºåŸŸï¼Œå¯¹åº”ç€å›¾åƒä¸­å¤§å—å¹³å¦çš„åŒºåŸŸï¼Œä¹Ÿå°±æ˜¯å¸¸è¯´çš„èƒŒæ™¯ï¼Œæ˜¯å›¾åƒçš„**å¤§è‡´æ¦‚è²Œå’Œè½®å»“**ã€‚å›¾åƒé«˜é¢‘ä¿¡æ¯è¡¨ç¤ºå›¾åƒä¸­ç°åº¦å€¼å˜åŒ–å‰§çƒˆçš„åŒºåŸŸï¼Œå¯¹åº”ç€å›¾åƒçš„**è¾¹ç¼˜ã€å™ªå£°ä»¥åŠç»†èŠ‚**éƒ¨åˆ†ï¼Œååº”çš„æ˜¯å°èŒƒå›´çš„ç»†èŠ‚ä¿¡æ¯ã€‚ä½†åœ¨å›¾åƒä¸­å¾ˆå¤šçš„é«˜é¢‘ä¿¡æ¯äººç±»æ˜¯å¾ˆéš¾æ„Ÿè§‰åˆ°çš„ã€‚

### cross-attention

attentionå›é¡¾ï¼š
attentionå°±æ˜¯å¸¦æƒæ±‚å’Œï¼Œå³attentionå‡½æ•°çš„outputæ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œæ¯ä¸ªvalueçš„æƒé‡æ˜¯è¿™ä¸ªvalueå¯¹åº”çš„keyå’Œqueryçš„ç›¸ä¼¼åº¦è®¡ç®—è€Œå¾—ã€‚

**æ¦‚å¿µï¼š**

- Transformeræ¶æ„ä¸­æ··åˆä¸¤ç§ä¸åŒåµŒå…¥åºåˆ—çš„attentionæœºåˆ¶
- ä¸¤ä¸ªåºåˆ—å¯ä»¥æ˜¯ä¸åŒçš„æ¨¡å¼å½¢æ€ï¼ˆå¦‚ï¼šæ–‡æœ¬ã€å£°éŸ³ã€å›¾åƒï¼‰
- ä¸¤ä¸ªåºåˆ—å¿…é¡»ç»´åº¦ç›¸åŒ
- ä¸€ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥çš„Qï¼Œå®šä¹‰äº†è¾“å‡ºçš„åºåˆ—é•¿åº¦ï¼Œå¦ä¸€ä¸ªåºåˆ—æä¾›è¾“å…¥çš„Kå’ŒV

**cross-attentionå’Œself-attentionï¼š**

self-attnè¡¨ç¤ºQKVæ¥è‡ªåŒä¸€ä¸ªåœ°æ–¹ï¼Œå¦‚æœæœ‰ä¸€ä¸ªåºåˆ—Xï¼Œä¾¿å¾—åˆ°ï¼š
$$
Q=W^QX\\
K=W^KX\\
V=W^VX
$$

cross-attnè¡¨ç¤ºQKVæ¥è‡ªä¸åŒçš„åœ°æ–¹ï¼Œå…¶ä¸­ä¸€ä¸ªåºåˆ—ç”¨ä½œæŸ¥è¯¢Qè¾“å…¥ï¼Œå¦ä¸€ä¸ªåºåˆ—ç”¨ä½œKå’ŒVè¾“å…¥,QKVæ˜¯ç”±ä¸¤ä¸ªåºåˆ—æ‹¼å‡‘çš„ã€‚
$$
Q=W^QX_1\\
K=W^KX_2\\
V=W^VX_2
$$

---

Transformeræ¶æ„ä¸­ï¼Œencoderä¸­çš„attentionä¸ºself-attentionï¼ˆå…¶è¾“å…¥æ˜¯å°†inputå¤åˆ¶ä¸‰ä»½å¾—åˆ°çš„QKVï¼‰ï¼Œdecoderä¸­ç¬¬ä¸€ä¸ªattentionä¸ºmasked-self-attentionï¼ˆä¸encoderåŒç†ï¼‰ï¼Œç¬¬äºŒä¸ªattentionä¸ºcross-attentionï¼ˆå…¶è¾“å…¥æ¥è‡ªä¸¤ä¸ªåœ°æ–¹ï¼Œqueryæ¥è‡ªdecoderä¸­ä¸Šä¸€å±‚çš„è¾“å‡ºx(å›¾ä¸­è²Œä¼¼æœ‰é—®é¢˜)ï¼Œkeyå’Œvalueæ¥è‡ªencoderçš„è¾“å‡ºm(ä¸ç„¶encoderç™½åšäº†)ï¼‰

$$
Q=W^Qx\\
K=W^Km\\
V=W^Vm
$$

**cross-attnç®—æ³•ï¼š**

$$
softmax((W_Q S_2)(W_K S_1)^T)Â·W_V S_1
$$

- æ‹¥æœ‰ä¸¤ä¸ªåºåˆ—S1ï¼ŒS2
- è®¡ç®—S1çš„Kå’ŒVï¼Œè®¡ç®—S2çš„Q
- æ ¹æ®Kå’ŒQè®¡ç®—æ³¨æ„åŠ›çŸ©é˜µ
- å°†Våº”ç”¨äºæ³¨æ„åŠ›çŸ©é˜µ
- è¾“å‡ºçš„åºåˆ—é•¿åº¦ä¸S2ä¸€è‡´

## 1. abstract

- å°†å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹åˆ†è§£ä¸ºï¼šdenoising autoencoder + DMs
- è¿™ç§è¿‡ç¨‹å…è®¸ä½¿ç”¨guiding mechanismæ¥æ§åˆ¶å›¾ç‰‡ç”Ÿæˆè€Œæ— éœ€é‡æ–°è®­ç»ƒ
- ä½†ä¸Šè¿°è¿™ç§æ¨¡å¼ä¸€èˆ¬éƒ½ç›´æ¥åœ¨pixel spaceä¸Šè¿›è¡Œæ“ä½œï¼Œå› æ­¤ï¼Œä¼˜åŒ–æ‰©æ•£æ¨¡å‹é€šå¸¸éœ€è¦æ¶ˆè€—å¤§é‡çš„è®¡ç®—èµ„æºï¼Œå¹¶ä¸”æ¨ç†çš„æ—¶å€™ä¹Ÿå¾ˆæ˜‚è´µ
- ä¸ºäº†é™ä½è®¡ç®—èµ„æºï¼ŒåŒæ—¶ä¿ç•™è´¨é‡å’Œçµæ´»æ€§ï¼Œä½œè€…å°†æ‰©æ•£æ¨¡å‹åº”ç”¨åœ¨å¼ºå¤§çš„é¢„è®­ç»ƒçš„autoencoderçš„latent spaceä¸Šã€‚è¿™åœ¨å¤æ‚åº¦é™ä½å’Œç»†èŠ‚ä¿ç•™ä¹‹é—´è¾¾åˆ°æœ€ä½³ç‚¹ã€‚
- æ–‡ç« å°†cross-attention layerå¼•å…¥æ¨¡å‹æ¶æ„ï¼Œå°†æ‰©æ•£æ¨¡å‹è½¬å˜ä¸ºå¼ºå¤§ä¸”çµæ´»çš„ç”Ÿæˆå™¨ã€‚è¿™ç§äº¤å‰æ³¨æ„åŠ›å±‚å¯ä»¥æ˜¯ä¸€ç§æ›´ä¸€èˆ¬å½¢å¼çš„æ¡ä»¶æ³¨å…¥ï¼Œå¯ä»¥æŠŠæ–‡æœ¬ã€è¾¹ç•Œæ¡†å’Œå›¾åƒé€šè¿‡ç»Ÿä¸€çš„æ–¹å¼æ³¨æ„åˆ°æ‰©æ•£æ¨¡å‹ä¸­

åŠ¨æœºï¼š
![å›¾ 6](../images/bb9adef09bcfe75c0db1657019ffb02e98e1195d9c285fb1dd100582e0d87ec7.png)  

## 2. introduction

- å›¾ç‰‡ç”Ÿæˆè¿™ä¸¤å¹´å‘å±•è´¼å¿«ï¼Œä½†åŒæ—¶ä¹Ÿæ˜¯æœ€è€—è´¹è®¡ç®—èµ„æºçš„åº”ç”¨ï¼Œå°¤å…¶æ˜¯å¤æ‚çš„ã€è‡ªç„¶åœºæ™¯çš„é«˜åˆ†è¾¨ç‡(high-resolution)å›¾åƒç”Ÿæˆï¼Œè¿™é€šå¸¸æ˜¯é€šè¿‡æ‰©å¤§åŸºäºä¼¼ç„¶çš„æ¨¡å‹ï¼Œæ¯”å¦‚DALLEå’ŒVQ-VAEsç­‰è‡ªå›å½’çš„Transformerã€‚
- æ‰©æ•£æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ä¼šåƒGANsé‚£æ ·è®­ç»ƒä¸ç¨³å®šå’Œæ¨¡å¼å´©æºƒï¼Œç¬¬äºŒå¯ä»¥é€šè¿‡å¤§é‡çš„å‚æ•°å…±äº«ï¼Œå†å¯¹è‡ªç„¶å›¾åƒçš„é«˜åº¦å¤æ‚åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡çš„æ—¶å€™ï¼Œæ— éœ€åƒauto-regressiveæ¨¡å‹é‚£æ ·è®¾è®¡æ•°åäº¿çš„å‚æ•°ã€‚
- DMsæ˜¯likelihood-basedæ¨¡å‹ï¼Œä»–ä»¬å€¾å‘äºèŠ±è´¹è¿‡å¤šçš„å®¹é‡å’Œè®¡ç®—èµ„æºæ¥å¯¹éš¾ä»¥å¯Ÿè§‰çš„æ•°æ®ç»†èŠ‚ï¼ˆimperceptible detailsï¼‰è¿›è¡Œå»ºæ¨¡ã€‚

> æ‰©æ•£æ¨¡å‹è®¡ç®—éœ€æ±‚é‡å¾ˆé«˜ï¼Œè¿™æ˜¯å› ä¸ºæ‰€æœ‰çš„é©¬å°”ç§‘å¤«çŠ¶æ€éƒ½éœ€è¦ä¸€ç›´åœ¨å†…å­˜ä¸­è¿›è¡Œé¢„æµ‹ï¼Œè¿™æ„å‘³ç€å¤§å‹æ·±åº¦ç½‘ç»œçš„å¤šä¸ªå®ä¾‹ä¸€ç›´å­˜åœ¨å†…å­˜ä¸­ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹å¾€å¾€ä¼šé™·å…¥å›¾åƒæ•°æ®ä¸­ç»†ç²’åº¦çš„éš¾ä»¥å¯Ÿè§‰çš„ç»†èŠ‚ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ç§ç»†ç²’åº¦å›¾åƒç”Ÿæˆä¹Ÿæ˜¯DMçš„ä¼˜åŠ¿ä¹‹ä¸€ï¼Œå› æ­¤æœ‰äº›çŸ›ç›¾ã€‚

**departure to latent space**.

- å…ˆåˆ†æä¸€ä¸‹æ­¤å‰åœ¨åƒç´ ç©ºé—´è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼š

![å›¾ 20](../images/b8f3b48e4b858ddf0367273fad9d10b3e894892acb84c40d0eafeb20dd3dcfd1.png)  

æ­¤å›¾æç»˜äº†æ¨¡å‹çš„å‹ç¼©ç‡å’Œå¤±çœŸä¹‹é—´çš„æƒè¡¡ï¼Œæ¨ªè½´è¶Šå¤§ä»£è¡¨æºå¸¦çš„æ•°æ®é‡è¶Šå¤§ï¼Œçºµè½´è¶Šå¤§ä»£è¡¨å¤±çœŸè¶Šå¤§ï¼Œä»å³å¾€å·¦çœ‹ï¼Œæœ€å³è¾¹æ˜¯åŸå›¾ã€å¤±çœŸæœ€å°ï¼Œéšç€å‹ç¼©çš„è¿›è¡Œï¼Œå¤±çœŸé€æ¸å¢å¤§ï¼Œå‰æœŸæ„ŸçŸ¥å‹ç¼©é˜¶æ®µè™½ç„¶æ•°æ®é‡å‹ç¼©æ‰äº†å¾ˆå¤šï¼Œä½†æ˜¯å¤±çœŸå¹¶ä¸å¤šï¼Œå› ä¸ºæ­¤æ—¶AE+GANåœ¨å°½å¯èƒ½åœ°ä¿ç•™ç€åŸå§‹å›¾åƒçš„å½¢çŠ¶ä¿¡æ¯ï¼Œåªæ˜¯å¹²æ‰äº†ä¸€äº›ç»†èŠ‚(**é«˜é¢‘**ç»†èŠ‚ä¿¡æ¯)

**i.e. Most bits of a digital image correspond to imperceptible details.**

è¯¦ç»†è§£é‡Šï¼š

- å’Œå¤§å¤šæ•°åŸºäºä¼¼ç„¶çš„æ¨¡å‹ä¸€æ ·ï¼Œå­¦ä¹ è¿‡ç¨‹å¯å¤§æ¦‚åˆ†ä¸ºtwo stagesï¼šperceptual compression stage & semantic compression stage
- ==ç¬¬ä¸€ä¸ªæ˜¯æ„ŸçŸ¥å‹ç¼©é˜¶æ®µ==ï¼ˆperceptual compression stageï¼‰ï¼šå»é™¤å›¾ç‰‡ä¸­çš„é«˜é¢‘ä¿¡æ¯ï¼ˆç»†èŠ‚éƒ¨åˆ†ï¼‰ï¼Œä½†ä»ç„¶å­¦ä¹ åˆ°å¾ˆå°‘çš„è¯­ä¹‰å˜åŒ–ã€‚
  - åœ¨æ„ŸçŸ¥å‹ç¼©å­¦ä¹ é˜¶æ®µï¼Œå­¦ä¹ æ–¹æ³•å¿…é¡»é€šè¿‡å»é™¤é«˜é¢‘çš„ç»†èŠ‚å°†æ•°æ®å°è£…åˆ°æŠ½è±¡è¡¨ç¤ºä¸­ã€‚GANæ“…é•¿æä¾›è¿™ç§æ„ŸçŸ¥å‹ç¼©ã€‚æœ¬æ–‡é€šè¿‡å°†é«˜ç»´å†—ä½™æ•°æ®ä»åƒç´ ç©ºé—´æŠ•å½±åˆ°æ½œåœ¨ç©ºé—´æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æ½œåœ¨ç©ºé—´ä¸­çš„æ½œåœ¨å‘é‡æ˜¯åŸå§‹åƒç´ å›¾åƒçš„å‹ç¼©å½¢å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä»£æ›¿åŸå§‹å›¾åƒã€‚
  - æ›´å…·ä½“åœ°è¯´ï¼Œè‡ªåŠ¨ç¼–ç å™¨ (AE) ç»“æ„æ•è·æ„ŸçŸ¥å‹ç¼©ã€‚AE ä¸­çš„ç¼–ç å™¨å°†é«˜ç»´æ•°æ®æŠ•å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œè§£ç å™¨ä»æ½œåœ¨ç©ºé—´æ¢å¤å›¾åƒã€‚
- è¯­ä¹‰å‹ç¼©é˜¶æ®µï¼ˆsemantic compression stageï¼‰ï¼šå®é™…çš„ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ•°æ®çš„è¯­ä¹‰å’Œæ¦‚å¿µã€‚
  - å›¾åƒç”Ÿæˆç®—æ³•å¿…é¡»èƒ½å¤Ÿæ•è·æ•°æ®ä¸­å­˜åœ¨çš„è¯­ä¹‰ç»“æ„ï¼Œè¿™ç§æ¦‚å¿µå’Œè¯­ä¹‰ç»“æ„ä¿å­˜äº†å›¾åƒä¸­å„ç§å¯¹è±¡çš„ä¸Šä¸‹æ–‡å’Œç›¸äº’å…³ç³»ã€‚Transformeræ“…é•¿æ•è·æ–‡æœ¬å’Œå›¾ç‰‡ä¸­çš„è¯­ä¹‰ç»“æ„ï¼Œ
- æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¦–å…ˆæ‰¾åˆ°ä¸€ä¸ªæ„ŸçŸ¥ä¸Šç­‰æ•ˆä½†è®¡ç®—æ›´åˆé€‚çš„spaceï¼Œç„¶åæˆ‘ä»¬å°†åœ¨è¿™ä¸ªspaceä¸­è®­ç»ƒç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆçš„DMã€‚

ä¼˜ç‚¹ï¼š
åªéœ€è¦è®­ç»ƒä¸€æ¬¡é€šç”¨çš„è‡ªç¼–ç å™¨ï¼Œå°±å¯ä»¥å¤šæ¬¡ç”¨äºæ‰©æ•£æ¨¡å‹è®­ç»ƒæˆ–æ¢ç´¢ä¸åŒçš„ä»»åŠ¡ã€‚

## 3. Related work

Generative models

- GANå¯ä»¥å¯¹æœ‰è‰¯å¥½çš„æ„ŸçŸ¥è´¨é‡çš„é«˜åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œæœ‰æ•ˆçš„é‡‡æ ·ï¼Œä½†éš¾ä»¥è®­ç»ƒï¼Œéš¾ä»¥æ±‚å¾—å®Œæ•´çš„æ•°æ®åˆ†å¸ƒã€‚
- åŸºäºä¼¼ç„¶çš„æ–¹æ³•å¯ä»¥æœ‰è‰¯å¥½çš„å¯†åº¦ä¼°è®¡ï¼ŒVAEèƒ½å¤Ÿæœ‰æ•ˆåˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä½†é‡‡æ ·è´¨é‡æ¯”ä¸ä¸ŠGAN
- è‡ªå›å½’æ¨¡å‹åœ¨å¯†åº¦ä¼°è®¡ä¸Šæœ‰å¾ˆå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†è®¡ç®—å¤æ‚åº¦å¤ªé«˜ï¼Œåªèƒ½åšä½åˆ†è¾¨ç‡å›¾åƒ
- ç”±äºåŸºäºåƒç´ çš„å›¾åƒè¡¨ç¤ºåŒ…å«å‡ ä¹ä¸å¯å¯Ÿè§‰çš„é«˜é¢‘ç»†èŠ‚ï¼Œå› æ­¤æœ€å¤§ä¼¼ç„¶è®­ç»ƒä¼šèŠ±è´¹ä¸æˆæ¯”ä¾‹çš„å®¹é‡æ¥å¯¹ä»–ä»¬è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå¯¼è‡´è®­ç»ƒæ—¶é—´è¿‡é•¿
- DMæ—¢æœ‰å¾ˆå¥½çš„æ¦‚ç‡å¯†åº¦åˆ†å¸ƒï¼Œåˆæœ‰å¾ˆå¥½çš„é‡‡æ ·è´¨é‡

Two-Stage image synthesis

- ä¸ºäº†å‡è½»å•ä¸ªç”Ÿæˆæ–¹æ³•çš„ç¼ºç‚¹ï¼Œå¤§é‡çš„ç ”ç©¶ï¼ˆVQ-GANï¼ŒDALLEï¼‰éƒ½é€šè¿‡ä¸¤é˜¶æ®µçš„æ–¹æ³•å°†ä¸åŒæ–¹æ³•çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œå½¢æˆæ›´æœ‰æ•ˆã€æ€§èƒ½æ›´å¥½çš„æ¨¡å‹ã€‚

## 4. method

![picture 0](../images/6011c94d7f6eb0d6099bb1d48452d512683eaa09d74e634d0a482050e39af569.png)  

The switch is used to control between different types of conditioning inputs:

- text inputsï¼šfirst converted into embeddings using a language model ğœÎ¸ (e.g. BERT, CLIP), and then they are mapped into the U-Net via the (multi-head) Attention(Q, K, V) layer.
- other spatially aligned inputs (e.g. semantic maps, images, inpainting), the conditioning can be done using concatenation.(å³ä¸zT concat)


### 4.1 æ„ŸçŸ¥å‹ç¼©é˜¶æ®µ

> æ„ŸçŸ¥å‹ç¼©ä¸»è¦åˆ©ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„è‡ªç¼–ç æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸€ä¸ªåœ¨æ„ŸçŸ¥ä¸Šç­‰åŒäºå›¾åƒç©ºé—´çš„æ½œåœ¨è¡¨ç¤ºç©ºé—´ã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªä¼˜åŠ¿æ˜¯åªéœ€è¦è®­ç»ƒä¸€ä¸ªé€šç”¨çš„è‡ªç¼–ç æ¨¡å‹ï¼Œå°±å¯ä»¥ç”¨äºä¸åŒçš„æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒï¼Œåœ¨ä¸åŒçš„ä»»åŠ¡ä¸Šä½¿ç”¨ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ„ŸçŸ¥å‹ç¼©çš„æ–¹æ³•é™¤äº†åº”ç”¨åœ¨æ ‡å‡†çš„æ— æ¡ä»¶å›¾ç‰‡ç”Ÿæˆå¤–ï¼Œä¹Ÿå¯ä»¥ååˆ†æ–¹ä¾¿çš„æ‹“å±•åˆ°å„ç§å›¾åƒåˆ°å›¾åƒï¼ˆinpaintingï¼Œsuper-resolutionï¼‰å’Œæ–‡æœ¬åˆ°å›¾åƒï¼ˆtext-to-imageï¼‰ä»»åŠ¡ä¸Šã€‚

æ„ŸçŸ¥å‹ç¼©åŸºäºVQ-GANï¼ŒåŒ…æ‹¬ä¸€ä¸ªAutoEncoderï¼Œè¿™ä¸ªAutoEncoderç”±æ„ŸçŸ¥æŸå¤±ï¼ˆperceptual lossï¼‰å’ŒåŸºäºè¡¥ä¸çš„å¯¹æŠ—æ€§ç›®æ ‡ï¼ˆpatch-based adversarial objectiveï¼‰çš„ç»„åˆè®­ç»ƒè€Œæˆã€‚è¿™ç¡®ä¿äº†é€šè¿‡å¼ºåˆ¶å±€éƒ¨çœŸå®æ€§å°†é‡å»ºé™åˆ¶åœ¨å›¾åƒæµè¡Œä¸Šï¼Œå¹¶é¿å…äº†ä»…ä¾èµ–äºåƒç´ ç©ºé—´æŸå¤±ï¼ˆå¦‚L2æˆ–L1æŸå¤±ï¼‰è€Œå¼•å…¥çš„æ¨¡ç³Šæ€§ã€‚

å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªimage x [H,W,3]ï¼Œencoder $\mathcal{E}$å°†å…¶ç¼–ç ä¸ºlatent representation $z=\mathcal{E}(x)$ï¼Œ(å…¶ä¸­z [h,w,c])ï¼Œç„¶ådecoder $\mathcal{D}$ä»éšç©ºé—´ä¸­å°†å›¾ç‰‡é‡å»ºå‡ºæ¥ï¼Œå¾—åˆ°$\tilde{x}=\mathcal{D}(z)=\mathcal{D(\mathcal{E(x)})}$ï¼Œ(å…¶ä¸­z [h,w,c])ã€‚é‡è¦çš„æ˜¯ï¼Œencoderé€šè¿‡ä¸‹é‡‡æ ·å› å­$f=H/h=W/w$å¯¹å›¾ç‰‡è¿›è¡Œä¸‹é‡‡æ ·ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸åŒçš„ä¸‹é‡‡æ ·å› å­çš„å½±å“ï¼ˆ$f=2^m, m\in N$ï¼‰

ä¸ºäº†é¿å…latent spaceçš„é«˜æ–¹å·®(ä»»æ„çš„ç¼©æ”¾)ï¼ˆæ˜¯è¯´ç±»ä¼¼äºVAEè®©éšç©ºé—´è§„åˆ™åŒ–å—ï¼Ÿi think yesï¼‰ï¼Œæ–‡ç« å¯¹latent zå®éªŒå¯¹æ¯”äº†ä¸¤ç§æ­£åˆ™åŒ–æŸå¤±é¡¹æ¥ç¼©å°æ–¹å·®ï¼š
>æ–¹å·®ç”¨æ¥æè¿°ä¸€ä¸ªæ¨¡å‹åœ¨ä¸åŒè®­ç»ƒé›†ä¸Šçš„å·®å¼‚ï¼Œè¡¨ç¤ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›æ–¹å·®è¶Šå¤§ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›è¶Šå¼±ï¼Œæ„å‘³ç€è¿‡æ‹Ÿåˆã€‚æ‰€ä»¥éœ€è¦ä½¿ç”¨æ­£åˆ™åŒ–é¡¹é¿å…é«˜æ–¹å·®ã€‚

$KL\text{-}reg.$ï¼šç±»ä¼¼äºVAEï¼Œå¯¹å­¦ä¹ åˆ°æ½œç©ºé—´çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒä½¿ç”¨ä¸€ä¸ªè½»å¾®çš„KLæƒ©ç½šé¡¹ã€‚
$VQ\text{-}reg.$ï¼šåœ¨decoderä¸­ä½¿ç”¨vector quantization layerï¼›è¿™ç±»ä¼¼äºVQ-GANï¼Œä½†quantizationå±‚åœ¨decoderä¸­ã€‚

ç”±äºåç»­çš„æ‰©æ•£æ¨¡å‹ç”¨äºå¤„ç†æ½œåœ¨ç©ºé—´zçš„äºŒç»´ç»“æ„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸å¯¹æ¸©å’Œçš„å‹ç¼©ç‡å°±å¯ä»¥å®ç°éå¸¸å¥½çš„é‡å»ºã€‚è¿™ä¸ä¹‹å‰çš„VQGANã€DALLEç›¸æ¯”ï¼Œä»–ä»¬ä¾èµ–äºå­¦ä¹ åˆ°çš„ç©ºé—´zçš„ä»»æ„1Dæ’åºæ¥å¯¹å…¶åˆ†å¸ƒè¿›è¡Œè‡ªå›å½’å»ºæ¨¡ï¼Œä»è€Œå¿½ç•¥äº†zçš„å¤§éƒ¨åˆ†å›ºæœ‰ç»“æ„ã€‚å› æ­¤ï¼Œæœ¬æ–‡çš„å‹ç¼©æ¨¡å‹å¯ä»¥æ›´å¥½åœ°ä¿ç•™xçš„ç»†èŠ‚ã€‚==ques è¿™å°±æ˜¯é‚£ä¸ªbias å…ˆéªŒï¼Ÿ==

---

#### G.Details on Autoencoder Models

- æˆ‘ä»¬æŒ‰ç…§VQ-GANä»¥å¯¹æŠ—çš„æ–¹å¼è®­ç»ƒçš„autoencoderï¼Œè¿™æ ·åŸºäºè¡¥ä¸çš„ï¼ˆpatch-basedï¼‰åˆ¤åˆ«å™¨$D_\psi$è¢«ç”¨æ¥åŒºåˆ†åŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒ$\mathcal{D}(\mathcal{E}(x))$
- ä½œè€…ä¸ºäº†é¿å…latent spaceçš„ä»»æ„ç¼©æ”¾ï¼ˆé«˜æ–¹å·®ï¼‰ï¼Œä½œè€…å°†latent zæ­£åˆ™ä¸ºä»¥0ä¸ºä¸­å¿ƒï¼Œå¹¶ä¸”é€šè¿‡æ­£åˆ™é¡¹$L_reg$ä½¿zçš„æ–¹å·®é™ä½ï¼Œæ­¤å¤„æœ‰ä¸¤ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆä¸¤ä¸ªæ­£åˆ™é¡¹ï¼‰ï¼š
  - ç¬¬ä¸€ç§ï¼šåˆ†å¸ƒ$q_\mathcal{E}(z|x)=\mathcal{N}(z;\mathcal{E}_\mu, \mathcal{E}_{\sigma^2})$å’Œæ ‡å‡†æ­£æ€åˆ†å¸ƒ$\mathcal{N}(z;0,1)$ä¹‹é—´çš„KLæ•£åº¦ï¼ˆå€Ÿé‰´äºVAEï¼‰ï¼Œqåˆ†å¸ƒæ˜¯å°†xç¼–ç ä¸ºæ½œåœ¨å˜é‡zçš„åˆ†å¸ƒp(z|x)çš„è¿‘ä¼¼åˆ†å¸ƒï¼Œç›®çš„æ˜¯è®©æˆ‘ä»¬çš„è¿‘ä¼¼åˆ†å¸ƒè¶Šæ¥è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒè¶Šå¥½ï¼Œè¿™æ ·latent spaceå°±æ¯”è¾ƒè§„åˆ™äº†ï¼›
  - ç¬¬äºŒç§ï¼šç”¨vector quantization layeræ¥æ­£åˆ™åŒ–latent spaceï¼Œè¿™ä¸ªVQå±‚æ˜¯é€šè¿‡å­¦ä¹ |Z|ä¸ªä¸åŒexemplarsçš„codebookå¾—åˆ°ï¼›

![å›¾ 2](../images/81a369f9cfce517766b6b0c1ad0370006044d53357801ce12d3a02a5e50f05a4.png)  

### 4.2 Latent diffusion models

- æˆ‘ä»¬åœ¨perceptual compressioné˜¶æ®µè®­ç»ƒå¥½äº†encoderå’Œdecoderæ¨¡å‹ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªé«˜æ•ˆçš„ã€ä½ç»´åº¦çš„latent spaceï¼Œå…¶ä¸­é«˜é¢‘çš„ã€éš¾ä»¥å¯Ÿè§‰çš„ç»†èŠ‚è¢«æŠ½è±¡æ‰äº†ã€‚
  - ä¸é«˜ç»´åº¦çš„pixel spaceç›¸æ¯”ï¼Œéšç©ºé—´æ›´é€‚åˆåŸºäºä¼¼ç„¶çš„ç”Ÿæˆæ¨¡å‹ï¼Œå› ä¸ºï¼šï¼ˆ1ï¼‰ç°åœ¨å¯ä»¥ä¸“æ³¨äºæ•°æ®çš„é‡è¦è¯­ä¹‰æ•°æ®ï¼›ï¼ˆ2ï¼‰åœ¨ä½ç»´åº¦ã€è®¡ç®—æ•ˆç‡æ›´é«˜çš„ç©ºé—´ä¸­è¿›è¡Œè®­ç»ƒã€‚
- ä¸ä¹‹å‰çš„è‡ªå›å½’æ¨¡å‹(DALLE)ã€åŸºäºæ³¨æ„åŠ›çš„é«˜åº¦å‹ç¼©çš„æ¨¡å‹å’Œåˆ†ç¦»éšç©ºé—´(VQGAN)ä¸åŒï¼Œæœ¬æ–‡å¯ä»¥åˆ©ç”¨**æˆ‘ä»¬æ¨¡å‹æä¾›çš„ç‰¹å®šäºå›¾åƒçš„å½’çº³åå·®**ã€‚
  - è¿™åŒ…æ‹¬ä»2Då·ç§¯å±‚æ„å»ºåº•å±‚U-Netçš„èƒ½åŠ›
  - è¿›ä¸€æ­¥ä½¿ç”¨é‡æ–°åŠ æƒçš„ç•Œé™å°†ç›®æ ‡é›†ä¸­åœ¨æ„ŸçŸ¥æœ€ç›¸å…³çš„bitä¸Šï¼Œå†™ä½œä¸‹å¼ï¼š

DMsï¼š
$$
L_{DM}=\mathbb{E}_{x,\epsilon\sim \mathcal{N}(0,1), t}[||\epsilon-\epsilon_\theta(x_t,t)||^2]
$$

LDMsï¼š
$$
L_{LDM}:=\mathbb{E}_{\mathcal{E}(x),\epsilon\sim \mathcal{N}(0,1), t}[||\epsilon-\epsilon_\theta(z_t,t)||^2]
$$

> å°†xtæ”¹ä¸ºztï¼Œå› ä¸ºç°åœ¨çš„æ‰©æ•£è¿‡ç¨‹æ˜¯åœ¨latent spaceä¸Šè¿›è¡Œ
> xæ”¹ä¸º$\mathcal{E}(x)$

$\epsilon_\theta(Â·,t)$ä¸ºtime-conditional U-Netç½‘ç»œã€‚ç”±äºå‰å‘è¿‡ç¨‹æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ä»encoderä¸­é«˜æ•ˆåœ°è·å–ztï¼Œæ¥è‡ªp(z)çš„æ ·æœ¬å¯ä»¥é€šè¿‡decoderå•æ¬¡è§£ç åˆ°å›¾åƒç©ºé—´ã€‚

### 4.3 æ¡ä»¶æœºåˆ¶ Conditioning Mechanisms

- å’Œå…¶ä»–ç”Ÿæˆæ¨¡å‹ä¸€æ ·ï¼ŒDMä¹Ÿå¯ä»¥å¯¹æ¡ä»¶åˆ†å¸ƒå»ºæ¨¡ã€‚è¿™å¯é€šè¿‡**æ¡ä»¶å»å™ªè‡ªç¼–ç å™¨**$\epsilon_\theta(z_t, t, y)$å®ç°ï¼Œå¦‚æ­¤ä¾¿å¯é€šè¿‡yæ¥æ§åˆ¶å›¾ç‰‡åˆæˆã€‚
- æœ¬æ–‡é€šè¿‡åœ¨U-Netä¸»å¹²ç½‘ç»œä¸Šå¢åŠ äº†cross-attentionæœºåˆ¶æ¥å®ç°$\epsilon_\theta(z_t, t, y)$ï¼Œå°†æ‰©æ•£æ¨¡å‹è½¬å˜ä¸ºæ›´çµæ´»çš„æ¡ä»¶å›¾åƒç”Ÿæˆå™¨ã€‚
- ä¸ºäº†å¯¹ä¸åŒæ¨¡æ€çš„yè¿›è¡Œé¢„å¤„ç†ï¼ˆæ¯”å¦‚text promptï¼‰ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ª**é¢†åŸŸä¸“ç”¨ç¼–ç å™¨**(domain specific encoder) $\tau_\theta$ï¼Œå®ƒç”¨æ¥å°†yæ˜ å°„ä¸ºä¸€ä¸ªä¸­é—´è¡¨ç¤º(intermediate representation) $\tau_\theta(y)\in \mathbb{R}^{M\times d_\tau}$ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ–¹ä¾¿çš„å¼•å…¥å„ç§å½¢æ€çš„æ¡ä»¶ï¼ˆæ–‡æœ¬ã€ç±»åˆ«ã€layoutç­‰ï¼‰
  - è¿™ä¸ªé¢†åŸŸä¸“ç”¨ç¼–ç å™¨å¯¹äºtext-to-imageå’Œlayout-to-imageä»»åŠ¡ï¼Œå°±æ˜¯unmasked Transformerï¼Œå°†è¾“å…¥yè½¬æ¢ä¸ºï¼Œå¯¹äºä»¥å¯¹é½çš„å›¾ç‰‡ä¸ºæ¡ä»¶çš„ï¼ˆsemantic synthesisï¼Œsuper-resolution and inpaintingï¼‰é‡‡ç”¨çš„å°±æ˜¯ç¬¬ä¸€é˜¶æ®µçš„encoderã€‚
- æœ€ç»ˆæ¨¡å‹å°±å¯ä»¥**é€šè¿‡ä¸€ä¸ªcross-attentionå±‚æ˜ å°„å°†æ§åˆ¶ä¿¡æ¯$\tau_\theta(y)$èå…¥åˆ°UNetçš„ä¸­é—´å±‚**.
- cross-attentionå±‚å®ç°å¦‚ä¸‹ï¼š
$$
Attention(Q,K,V) = softmax(\dfrac{QK^T}{\sqrt{d}})Â·V\\
Q = W_Q^{(i)}Â·\varphi_i(z_t), K = W_K^{(i)}Â·\tau_\theta(y), V = W_V^{(i)}Â·\tau_\theta(y)
$$
å…¶ä¸­ï¼š

- $\varphi_i(z_t)\in \mathbb{R}^{N\times d_\epsilon^i}$ï¼Œztæ˜¯å¯¹latent codeæ­£å‘æ‰©æ•£çš„ç»“æœï¼Œç„¶å$\varphi_i(z_t)$ä»£è¡¨ç»è¿‡U-Netç½‘ç»œ$\epsilon_\theta$ä¹‹åflattenå¾—åˆ°çš„ä¸­é—´è¡¨å¾ï¼ˆU-Netå…±äº«å‚æ•°å§ï¼‰ï¼Œè¯¥åºåˆ—**ä½œä¸ºæŸ¥è¯¢Qè¾“å…¥**
- $\tau_\theta(y)\in \mathbb{R}^{M\times d_\tau}$ï¼Œyæ˜¯ä¸åŒæ¨¡æ€çš„æ¡ä»¶ï¼Œ$\tau_\theta$æ˜¯æŒ‡é¢†åŸŸä¸“ç”¨ç¼–ç å™¨ï¼Œå°†yæ˜ å°„ä¸ºä¸€ä¸ªä¸­é—´è¡¨ç¤ºï¼Œè¯¥åºåˆ—**ä½œä¸ºKå’ŒVè¾“å…¥**
- $ W_Q^{(i)}\in \mathbb{R}^{d\times d_\epsilon^i},  W_K^{(i)}\in \mathbb{R}^{d\times d_\tau},  W_V^{(i)}\in \mathbb{R}^{d\times d_\tau}$å’ŒTransformerä¸€æ ·ï¼Œæ˜¯å¯è®­ç»ƒå­¦ä¹ çš„å‚æ•°çŸ©é˜µï¼Œåº”è¯¥ä¹Ÿæ˜¯å…±äº«çš„å§ï¼ˆè¿™ä¸ªiæ˜¯ä¸åŒstepï¼Œè¿˜æ˜¯ä¸åŒçš„å¤´å‘¢ï¼‰

> ç”¨æ¯ä¸€ä¸ªqä¸ä¸åŒçš„Kè®¡ç®—å†…ç§¯é™¤ä»¥æ ¹å·ï¼Œç»è¿‡softmaxå¾—åˆ°å¯¹åº”çš„æƒé‡ï¼Œå°†æƒé‡å’ŒVåŠ æƒæ±‚å’Œå¾—åˆ°è¯¥qçš„è¾“å‡ºï¼Œæ€»çš„å¾—åˆ°æ‰€æœ‰çš„Qçš„è¾“å‡º

åŸºäºimage-conditioningå¯¹ï¼Œæˆ‘ä»¬é€šè¿‡ä¸‹å¼å­¦ä¹ conditional LDMï¼š
$$
L_{LDM}:=\mathbb{E}_{\mathcal{E}(x),y ,\epsilon\sim \mathcal{N}(0,1), t}[||\epsilon-\epsilon_\theta(z_t,t,\tau_\theta(y))||^2]
$$
é¢†åŸŸä¸“ç”¨ç¼–ç å™¨$\tau_\theta$å’Œå»å™ªU-Netç½‘ç»œ$\epsilon_\theta$éƒ½å¯ä»¥é€šè¿‡ä¸Šè¿°æŸå¤±å‡½æ•°è¿›è¡Œè”åˆä¼˜åŒ–ã€‚
è¿™ç§è°ƒèŠ‚æœºåˆ¶éå¸¸çµæ´»ï¼Œå› ä¸º$\tau_\theta$å¯ä»¥ç”±ç‰¹å®šé¢†åŸŸçš„ä¸“å®¶ï¼ˆäººè¿˜æ˜¯æ¨¡å‹==quesï¼Ÿ==ï¼‰è¿›è¡Œå‚æ•°åŒ–ã€‚æ¯”å¦‚å½“yæ˜¯text promptçš„æ—¶å€™ï¼Œå¯ä»¥ç”¨unmaskedçš„Transformerè¿›è¡Œå‚æ•°åŒ–ã€‚

## 5. å®éªŒ

- æœ¬æ–‡åˆ†æäº†æ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†æ–¹é¢ï¼Œlatent-basedä¸pixel-basedçš„æ‰©æ•£æ¨¡å‹ç›¸æ¯”å…·å¤‡çš„ä¼˜åŠ¿ã€‚
- æœ‰è¶£çš„æ˜¯ï¼Œä½œè€…å‘ç°åœ¨å¯¹æ½œåœ¨ç©ºé—´è¿›è¡ŒVQ-regæ­£åˆ™åŒ–æ—¶ï¼Œå¯ä»¥å¾—åˆ°æ¯”DMsæ›´å¥½çš„é‡‡æ ·è´¨é‡ï¼Œå³ä½¿VQæ­£åˆ™åŒ–ç¬¬ä¸€é˜¶æ®µçš„é‡å»ºèƒ½åŠ›ç¨å¾®è½åäºcontinuous counterpart;==è§è¡¨8==

### 5.1 æ„ŸçŸ¥å‹ç¼©å‡è¡¡

- è¿™éƒ¨åˆ†åˆ†æäº†å…·æœ‰ä¸åŒä¸‹é‡‡æ ·å› å­fï¼ˆ1,2,4,8,16,32ï¼‰çš„LDMçš„è¡Œä¸ºï¼Œç®€å†™ä¸ºLDM-fï¼ŒLDM-1ä»£è¡¨pixel-based DMsã€‚
- è¡¨8æ˜¾ç¤ºäº†ä¸åŒLDMçš„ç¬¬ä¸€é˜¶æ®µæ¨¡å‹çš„è¶…å‚æ•°å’Œé‡å»ºèƒ½åŠ›ã€‚
- å›¾6æ˜¾ç¤ºäº†åœ¨ImageNetæ•°æ®é›†ä¸Šï¼Œ200ä¸‡æ­¥train stepçš„ä»¥ç±»åˆ«ä¸ºæ¡ä»¶çš„æ¨¡å‹çš„æ ·æœ¬è´¨é‡ä¸è®­ç»ƒè¿›åº¦çš„å…³ç³»
  - å°çš„ä¸‹é‡‡æ ·å› å­(LDM-1,LDM-2)ä¼šå¯¼è‡´è®­ç»ƒé€Ÿåº¦ç¼“æ…¢
  - è¿‡å¤§çš„ä¸‹é‡‡æ ·å› å­ä¼šå¯¼è‡´ä¿çœŸåº¦åœæ»ä¸å‰ï¼ˆå½“è®­ç»ƒè¾ƒå°‘çš„æ­¥æ•°ä¹‹åï¼‰
- è§‚å¯Ÿå›¾ä¸€å’Œå›¾äºŒçš„åˆ†æï¼Œæˆ‘ä»¬å°†å…¶å½’å› äºï¼š
  - **å°†å¤§éƒ¨åˆ†æ„ŸçŸ¥å‹ç¼©ç•™ç»™æ‰©æ•£æ¨¡å‹**
  - **å¦‚æœç¬¬ä¸€é˜¶æ®µçš„å‹ç¼©è¿‡äºå¼ºå¤§ï¼Œä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œä»è€Œé™åˆ¶å›¾ç‰‡çš„è´¨é‡**
- LDM-{4-16}åœ¨æ•ˆç‡å’Œæ„ŸçŸ¥ä¸Šä¿çœŸåº¦çš„ç»“æœä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ï¼Œè¿™è¡¨ç°åœ¨ï¼šåŸºäºåƒç´ çš„æ‰©æ•£LMD-1å’ŒLDM-8åœ¨200ä¸‡æ­¥è®­ç»ƒæ­¥æ•°ä¹‹åçš„FIDå·®è·æ˜æ˜¾ï¼Œè¾¾åˆ°38.

![å›¾ 2](../images/245186c6e1dab36473a08e8e23bd695f318ef32f515be5013f24162784b230e6.png)  
> ç”±å›¾6å¯è§ï¼š
>
> 1. LDM-1å’ŒLDM-{4-16}ç›¸æ¯”ï¼Œæƒ³ä½¿ç”Ÿæˆå›¾ç‰‡è¾¾åˆ°ç›¸åŒçš„è´¨é‡ï¼Œéœ€è¦æ›´é•¿çš„è®­ç»ƒæ—¶é—´
> 2. è¿‡å¤šçš„æ„ŸçŸ¥å‹ç¼©ï¼ˆå¦‚LDM-32æ‰€ç¤ºï¼‰ï¼Œä¼šé™åˆ¶ç”Ÿæˆå›¾ç‰‡çš„è´¨é‡

### 5.2 ä½¿ç”¨latent diffusionçš„å›¾ç‰‡ç”Ÿæˆ

- æœ¬æ–‡åœ¨CelebA-HQï¼ŒFFHQï¼ŒLSUN-Churcheså’ŒLSUN-Bedroomsä¸Šè®­ç»ƒ256*256å›¾ç‰‡çš„æ— æ¡ä»¶æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨FIDå’ŒPrecision-and-RecallæŒ‡æ ‡æ¥è¯„ä¼°å›¾ç‰‡ç”Ÿæˆèƒ½åŠ›
  - åœ¨CeleA-HQæ•°æ®é›†ä¸Šè·å¾—SOTAçš„æˆç»©
  - åœ¨LSUN-Bedroomä¸Šåˆ†æ•°æ¥è¿‘ADMï¼ˆdiffusion models beat GANsï¼‰ï¼Œä½†æ˜¯æˆ‘ä»¬çš„å‚æ•°é‡å‡å°‘ä¸€åŠï¼Œæ‰€éœ€è®¡ç®—èµ„æºå‡å°‘äº†4å€ã€‚
- å®šæ€§å›¾ç‰‡è§å›¾4.

![å›¾ 3](../images/021f149f67202788554315e8190e2d37cf556277c4bec8fcbc6dd47523e78619.png)  

### 5.3 Conditional Latent Diffusion

#### 5.3.1 Transformer Encoders for LDMs

- é€šè¿‡å°†cross-attnå¼•å…¥LDMï¼Œæˆ‘ä»¬ä¸ºæ‰©æ•£æ¨¡å‹æ‰“å¼€äº†ä»¥å‰æ²¡æ¢ç´¢è¿‡çš„ä¸åŒçš„æ¡ä»¶ç”Ÿæˆæ¨¡å¼ã€‚
- å¯¹äº**text-to-image**ï¼Œåœ¨LAION-400Mæ•°æ®é›†ä¸Šè®­ç»ƒäº†ä¸€ä¸ªtext promptçš„åŠ äº†KLæ­£åˆ™åŒ–çš„LDMã€‚æˆ‘ä»¬ä½¿ç”¨BERT-tokenizerï¼ˆåˆ†è¯å™¨ï¼‰ï¼Œå¹¶å°†$\tau_\theta$ä½œä¸ºä¸€ä¸ªTransformeræ¥å¾—åˆ°latent codeï¼Œå®ƒé€šè¿‡ï¼ˆå¤šå¤´ï¼‰cross-attnè¢«æ˜ å°„åˆ°U-Netä¸­ã€‚ç»“æœå¦‚ä¸‹ï¼š
![å›¾ 4](../images/922f0e69d2494d798e6acb5f493d7f9db2e341b7523748d367b355f67f610390.png)  
ç”±table 2å¯è§ï¼Œå‚æ•°é‡å°‘å¾ˆå¤šï¼Œä½†æ•ˆæœç›¸å½“ã€‚è¿™ä¸ªG*æ˜¯æŒ‡ä½¿ç”¨classifier-free guidanceï¼Œä½œè€…ä¹Ÿå‘ç°åŠ ä¸Šè¿™ä¸ªä¹‹åï¼Œé‡‡æ ·è´¨é‡å¤§å¹…åº¦æå‡ã€‚
- å¯¹äº**layout-to-image**ï¼Œåœ¨OpenImageæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç„¶åå†COCOä¸Šå¾®è°ƒï¼Œåœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†SOTAï¼›
![å›¾ 5](../images/eb5ef202b1a3a2a6c80deb9829406a57c414c5ee7c0a2b9c2ff84eed96b2f44f.png)  
![å›¾ 6](../images/ebf589e05c04210105c9cef0434d79a33f8d2e809061ffcdd90f9ac2f2f21d0c.png)  

### 5.4 Super-Resolution with LD

## 6. limitations

è™½ç„¶ä¸åŸºäºåƒç´ çš„æ–¹æ³•ç›¸æ¯”ï¼ŒLDM æ˜¾ç€é™ä½äº†è®¡ç®—è¦æ±‚ï¼Œä½†å®ƒä»¬çš„é¡ºåºé‡‡æ ·è¿‡ç¨‹ä»ç„¶æ¯” GAN æ…¢ã€‚

## Code

### 1. UNetModel

UNetModelé‡Œé¢é€šè¿‡DownSampleå’ŒUnSampleè¿›è¡Œä¸‹ä¸Šé‡‡æ ·ï¼Œç„¶åæœ€å¤šçš„å°±æ˜¯ResBlockå’ŒSpatialTransformerï¼ŒUNetä¸æ”¹å˜è¾“å…¥è¾“å‡ºçš„å¤§å°ã€‚

ResBlockæ¥å—ä¸Šä¸€æ¨¡å—çš„è¾“å…¥åŠtimestep embeddingï¼›
SpatialTransformeræ¥å—ä¸Šä¸€æ¨¡å—çš„è¾“å…¥åŠcontext embeddingï¼Œæ­¤æ¨¡å—è¿›è¡Œcross-attnå­¦ä¹ contextä¸imageä¹‹é—´çš„å…³ç³»ï¼›

![picture 1](../images/024fabba91d4d6ebca2f83ab7aab03be73b8b13533a59342e19ad861bc807e19.png)  
[complete pic](https://s2.51cto.com/images/blog/202303/18001153_64149149a7eb377271.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp)

**ResBlock**:
![picture 2](../images/9ff1d3abaed7941d03dfcf83907b6ae46c21be1f1a9000d79d07f0ccfa2fe9b0.png)  

**TimeEmbedding**å³Transformerä¸­çš„positional embedding (sinusoidal timestep embeddings)
![picture 3](../images/ca4c42df1f3f363b34cb03a17d998cbf6cf52ce682e2f44f3daca4e1afd4e032.png)  

**TextEmbedding**ä½¿ç”¨CLIPçš„text encoder
![picture 4](../images/93ccb888ce4ccada5dece92e5e9945a5b8094a006adf346762eeb2954f9b1806.png)  

**Spatial Transformer**
åœ¨ CrossAttention æ¨¡å—ä¸­ï¼Œå›¾åƒä¿¡æ¯ä½œä¸º Queryï¼Œæ–‡æœ¬ä¿¡æ¯ä½œä¸º Key & Valueï¼Œæ¨¡å‹ä¼šå…³æ³¨å›¾åƒå’Œæ–‡æœ¬å„éƒ¨åˆ†å†…å®¹çš„ç›¸å…³æ€§
![picture 5](../images/7c94a52f5a0b5037e41b326b77b5a9a42c57791e0281366cbd19b5aa38f99e7b.png)  

reference
[medium tutorial](https://medium.com/@steinsfu/stable-diffusion-clearly-explained-ed008044e07e)
[code tutorial](https://zhuanlan.zhihu.com/p/613337342)